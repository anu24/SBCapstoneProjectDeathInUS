---
title: "Decision Tree Model"
author: "Anushree Shivarudrappa"
date: "June 15, 2016"
output: pdf_document
---

# 1. Pre-Processing
```{r, warning=FALSE, message=FALSE}
library(data.table)
library(ggplot2)
library(dplyr)
library(scales)
library(RColorBrewer)
library(tidyr)
library(caTools)
library(rpart)
library(rpart.plot)
library(ROCR)
library(randomForest)
library(tree)
library(caret)
library(e1071)
```

# 2. Data Loading
```{r, echo=FALSE}
setwd("/Users/anushreeshivarudrappa/Desktop/Spring Board/SB Capstone DeathRecords DataSet")
```
```{r, message=FALSE, warning=FALSE,results='hide'}
Death_US <- fread("DeathRecords.csv", header = T)

```

```{r, echo=FALSE}
setwd("/Users/anushreeshivarudrappa/Desktop/Spring Board/SB Capstone Project")
```

# 3. Selecting dataset for model

```{r}
# separates natural death
Death_US_natural <- Death_US[Death_US$MannerOfDeath == 7, ]

```

## Select required variables

```{r,warning=FALSE, message=FALSE}
require(MASS)
require(dplyr)
natural_sub <- Death_US_natural %>% dplyr::select(Education2003Revision, Sex, Age, 
                      InfantAgeRecode22, 
                      PlaceOfDeathAndDecedentsStatus, MaritalStatus, InjuryAtWork,
                      Autopsy, ActivityCode, PlaceOfInjury, Icd10Code,CauseRecode358,
                      CauseRecode113, InfantCauseRecode130,CauseRecode39,
                      NumberOfEntityAxisConditions,NumberOfRecordAxisConditions,Race)

str(natural_sub)
```

## Converting Character variable into Integer variable
```{r, warning=FALSE}
natural_sub$Sex <- as.integer(as.factor(natural_sub$Sex)) 
natural_sub$MaritalStatus <- as.integer(as.factor(natural_sub$MaritalStatus))
natural_sub$InjuryAtWork <- as.integer(as.factor(natural_sub$InjuryAtWork))
natural_sub$Autopsy <- gsub("n", "N", natural_sub$Autopsy)
natural_sub$Autopsy <- as.integer(as.factor(natural_sub$Autopsy))  
natural_sub$Icd10Code <- as.integer(as.factor(natural_sub$Icd10Code))  

```

As we analyzed, the feature variables are "Age + InfantAgeRecode22 + 
PlaceOfDeathAndDecedentsStatus + MaritalStatus + ActivityCode + PlaceOfInjury + 
NumberOfRecordAxisConditions + NumberOfEntityAxisConditions"

```{r,warning=FALSE}
# Since the decision tree support till 32 levels removing 7 levels which has less entries
table(factor(natural_sub$CauseRecode39))
CauseExtraRemove <- natural_sub[, natural_sub$CauseRecode39 %in% c(2, 40, 41, 42, 38, 35, 1)]
table(CauseExtraRemove)
# remove the 7 factors levels from Death_US_natural dataset
natural_sub <- natural_sub[!(CauseExtraRemove)]
nrow(natural_sub)

# model data
modeldata <- natural_sub

# We will do a random 70:30 split in our data set (70% will be for training models, 
# 30% to evaluate them)
set.seed(111)
# randomly pick 70% of the number of observations 
index <- sample.split(modeldata$CauseRecode39, SplitRatio = 0.7)
# subset data to include only the elements in the index
train <- subset(modeldata, index==T)
nrow(train)
# subset data to include all but the elements in the index
test <- subset(modeldata, index==F)
nrow(test)
# take a copy of ICD10Code of test set and remove the variable from test set
Cause39 <- test$CauseRecode39
test$CauseRecode39 <- NULL

```

## Model Decision Tree
```{r}
model_tree <- tree(as.factor(CauseRecode39) ~ Age + InfantAgeRecode22 + 
                     PlaceOfDeathAndDecedentsStatus + MaritalStatus + ActivityCode + 
                      PlaceOfInjury + NumberOfRecordAxisConditions + 
                      NumberOfEntityAxisConditions, train)

# plot model_tree
plot(model_tree)
text(model_tree, pretty = 0)

# Predict the test dataset using model
predict_ICD2 <- predict(model_tree, newdata = test, type = "class")
# confusion matrix
conf_matrix2 <- table(predict_ICD2, Cause39) 
```

**Model Accuracy**
```{r}
sum(diag(conf_matrix2)) / nrow(test) 
```

## Prune tree
Prune back the tree to avoid overfitting the data. Typically, you will want to select a tree size
that minimizes the cross-validated error
```{r}
# cross validation to check where to stop prunning
cvtree <- cv.tree(model_tree, FUN = prune.misclass)
names(cvtree)
plot(cvtree$size, cvtree$dev, type = "b",
     xlab = "Tree Size",
     ylab = "MSE") 
```
  
Since the lowest deviation is at tree size 3 which we already have in our model, there is no need to prune the tree